{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic function comparisons between the paper and code implementation (specfically `get_stationary_states_arange_x_homogenousNetwork.py`)\n",
    "\n",
    "To discretize the dynamic function updates, clever methods were utilized to update the variables using the Euler scheme. However, for compurational efficiency certain variables would be factored out of the code. \n",
    "Further, certain variables were scaled to speed up the simulation process. The combination is thus confusion for those who are not engaged with the code on a regular basis. \n",
    "Thus, this notebook aims to clarify some of the differences and how each equations are implemented in the code.\n",
    "\n",
    "Specifically, this notebook focuses on the model `get_stationary_states_arange_x_homogenousNetwork.py`, other models or scripts should be able to be extrapolated from the analysis on this model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation 5:\n",
    "\n",
    "### Paper's equation:\n",
    "![Alt text](image.png) \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "C_i \\frac{dV_i}{dt} & = g_{leak} (V_{rest} - V_i) + g_{syn, i}(t)(V_{syn} - V_i) + I_{stim}(t) + I_{noise, i}(t) \\\\\n",
    "\\implies dV_i & = \\frac{dt}{C_i} \\Big(  g_{leak} (V_{rest} - V_i) + g_{syn, i}(t)(V_{syn} - V_i) + I_{stim}(t) + I_{noise, i}(t) \\Big) \\\\\n",
    "  & = dt \\frac{1}{C_i} \\Big(  g_{leak} (V_{rest} - V_i) + g_{syn, i}(t)(V_{syn} - V_i) + I_{stim}(t) + I_{noise, i}(t) \\Big) \\\\ \n",
    "  & = dt \\frac{1}{C_i} \\Big(  g_{leak} (V_{rest} - V_i) + I_{noise, i}(t) + g_{syn, i}(t)(V_{syn} - V_i) + 0 \\Big) \\,\\,\\,\\because I_{stim}(t) = 0 \\,\\forall t \\\\ \n",
    "  & = dt \\frac{1}{C_i} \\Big(  g_{leak} (V_{rest} - V_i) + I_{noise, i}(t) + g_{exc, i}(t)(V_{exc} - V_i) + g_{inh, i}(t)(V_{inh} - V_i) \\Big) \\,\\,\\, \\because \\text{it can be decomposed to excitatory and inhibitory spiking components} \\\\\n",
    "  & = dt \\frac{1}{C_i} \\Big(  \\underbrace{g_{leak} (V_{rest} - V_i)}_{A} + \\underbrace{g_{noise, i}(t)(V_{noise} - V_i)}_{B} + \\underbrace{g_{exc, i}(t)(V_{exc} - V_i)}_{C} + \\underbrace{g_{inh, i}(t)(V_{inh} - V_i)}_{D} \\Big) \\\\\n",
    "\\\\\n",
    "& \\text{Now the formula is in a similar form as the code implementation.} \\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code implementation:\n",
    "```python\n",
    "## Line 191 in `get_stationary_states_arange_x_homogeneousNetwork.py'\n",
    "################################################################################\n",
    "v_Offset=ne.evaluate('1/tau*((Vrest-v) +(Vnoise-v)*Snoise+(Vexc-v)*Sexc+(Vinh-v)*Sinh)')\n",
    "\n",
    "## Line 211 in `get_stationary_states_arange_x_homogeneousNetwork.py'\n",
    "################################################################################\n",
    "v[neuronsNotAtRefractory]=v[neuronsNotAtRefractory]+dt*v_Offset[neuronsNotAtRefractory]\n",
    "```\n",
    "\n",
    "``` python\n",
    "## For clarify, they can be rewritten the following ways.\n",
    "################################################################################\n",
    "v_Offset=ne.evaluate(\n",
    "  '1/tau*( (Vrest-v) + \\\n",
    "           (Vnoise-v)*Snoise + \\\n",
    "           (Vexc-v)*Sexc + \\\n",
    "           (Vinh-v)*Sinh \\\n",
    "          )' \n",
    ")\n",
    "\n",
    "v[neuronsNotAtRefractory]=(\n",
    "  v[neuronsNotAtRefractory] + \n",
    "  dt*v_Offset[neuronsNotAtRefractory]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable `tau`: \n",
    "```python\n",
    "## Line 407-409 in 'functions_sim.py` ##\n",
    "################################################################################\n",
    "tau=np.random.normal( system_parameters['tauSTN'] , system_parameters['tauSTN']*system_parameters['sigmaP'], N )\n",
    "# and STN neurons\n",
    "tau[N_STN:]=np.random.normal( system_parameters['tauGPe'], system_parameters['tauGPe']*system_parameters['sigmaP'], N_GPe )\n",
    "```\n",
    "\n",
    "```python\n",
    "## Line 28, 42-45 in `functions_pars.py` ##\n",
    "################################################################################\n",
    "system_parameters.update({'sigmaP': 0.05 })\n",
    "\n",
    "# set timescale for STN neurons\n",
    "system_parameters.update({'tauSTN': 150})  # ms  \n",
    "# and STN neurons\n",
    "system_parameters.update({'tauGPe': 30.})  # ms \n",
    "\n",
    "```\n",
    "\n",
    "-  `tau` is an ndarray of length `N`, where `N` is the total number of neurons: 1000 + 2.\n",
    "- The first 1000 entries of the ndarray `tau` are instances of the random variable from `Norm(mean=tauSTN, std=tauSTN*sigmaP) = Norm(150, 150*0.05) = Norm(150, 7.5)`.\n",
    "- The last 2 entries of the ndarray `tau` are instances of the random variable from `Norm(mean=tauGPe, std=tauGPe*sigmaP) = Norm(30, 30*0.05) = Norm(30, 1.5)`.\n",
    "- By the forms of the equation from the paper and the code implementation, `tau` is equivalent to the $C_i$ (membrane capacitance) in the equation.\n",
    "- Values: \n",
    "  - Paper: \n",
    "    - $C_i \\stackrel{iid}{\\sim} Norm(\\mu_{C_i} = 3 \\frac{\\mu F}{cm^2}, \\,\\, \\sigma = (0.05 * \\mu_{C_i}) \\frac{\\mu F}{cm^2}) = Norm(3\\frac{\\mu F}{cm^2}, \\,\\, 0.15\\frac{\\mu F}{cm^2})$\n",
    "    - In the original Fortran code and other paper that we started replicating, only STN population was modeled.\n",
    "  - Code: \n",
    "    - For STN (first 1000 entries): $tau \\sim Norm(150, \\,\\, 7.5)$\n",
    "    - For GPe (last 2 entries): $tau \\sim Norm(30, \\,\\,\\, 1.5)$\n",
    "- Scaling:\n",
    "  - So `tau` or $C_i$ has been scaled by a factor of 50x:\n",
    "  - `3 * 50 = 150`, `0.15 * 50 = 7.5`\n",
    "- Questions: \n",
    "  - **??? Are the conductance for each of the components thereafter (A, B, C, D) also scaled by 50x to offset `tau`'s scaling? If so, does this method of decreasing the simulation computation time realistic?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable `Sleak` (or `g_leak`):\n",
    "- Siemens is the unit for conductance, hence the author denotes conductance with `S` in the code. \n",
    "- In the papers, conductance is denoted with `g`, hence \"leaky conductance\" is referred to as `g_leak`.\n",
    "- However, the variable is missing in the code because it is implicitly assumed to be `1 mS/cm^2`.\n",
    "- Values: \n",
    "    - Paper: \n",
    "        - `g_leak = 0.02 mS/cm^2`\n",
    "    - Code:\n",
    "        - Implicitly `1 mS/cm^2` because it is factored out in the code.\n",
    "- Scaling: \n",
    "    - As seen, the value used by the code is also a 50x scale of the value of the paper (`0.02 * 50 = 1`).\n",
    "    - Thus, in addition to `tau` being scaled by 50x, `g_leak` is also scaled by 50x to 1 and factored out of the code implementation of dynamic function 5.\n",
    "- Questions: \n",
    "    - In component A, the scaling of both `tau` and `g_leak` by a factor of 50x would cancel each other out mathematically, thus $(V_{rest} - V_i)$ is not scaled.\n",
    "    - **??? Do we see similar cancelling out in component B, C, and D?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable `Vrest`:\n",
    "- `Vrest` is an ndarray of length `N` where each of the value is VRestSTN = -38.0 mV.\n",
    "\n",
    "### Varaible `Vnoise`: \n",
    "- `Vnoise` is an ndarray of length `N` where the first N_STN=1000 values are Vexc=0. mV and the last 2 values are Vinh=-80. mV.\n",
    "\n",
    "### Variable `Vexc`:\n",
    "- `Vexc` is a float equal to 0. mV.\n",
    "\n",
    "### Variable `Vinh`:\n",
    "- `Vinh` is a float equal to -80. mV.\n",
    "\n",
    "### Variable `Snoise`:\n",
    "\n",
    "### Variable `Sexc`:\n",
    "\n",
    "### Variable `Sinh`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation 6: \n",
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation 7: \n",
    "![Alt text](image-2.png)\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tau_{syn} \\frac{d g_{syn, i}}{d t} & = -g_{syn, i} + \\kappa \\frac{\\tau_{syn}}{N} \\sum_{j \\in G_i} w_{j \\rightarrow i}(t) \\sum_{l^j} \\delta (t - t^j_{l^j} - t_a), \\,\\,\\, \\text{where } G_i := \\{\\text{All presynaptic neurons connected to neuron $i$}\\} \\\\\n",
    "\\\\\n",
    "\\implies dg_{syn, i} &= \\frac{dt}{\\tau_{syn}} \\left[ -g_{syn, i} + \\kappa \\frac{\\tau_{syn}}{N} \\sum_{j \\in G_i} w_{j \\rightarrow i}(t) \\sum_{l^j} \\delta (t - t^j_{l^j} - t_a) \\right] \\\\\n",
    "    & = \\left[ \\frac{dt}{\\tau_{syn}} \\cdot -g_{syn, i} \\right] + \\left[ \\frac{dt}{\\tau_{syn}} \\kappa \\frac{\\tau_{syn}}{N} \\sum_{j \\in G_i} w_{j \\rightarrow i}(t) \\sum_{l^j} \\delta (t - t^j_{l^j} - t_a) \\right] \\\\\n",
    "    & = dt \\cdot -\\left[ \\frac{g_{syn, i}}{\\tau_{syn}} \\right] + \\left[ \\frac{dt}{\\tau_{syn}} \\kappa \\frac{\\tau_{syn}}{N} \\sum_{j \\in G_i} w_{j \\rightarrow i}(t) \\sum_{l^j} \\delta (t - t^j_{l^j} - t_a) \\right] \\\\\n",
    "    & = dt \\cdot -\\left[ \\frac{g_{syn, i}}{\\tau_{syn}} \\right] + dt \\cdot \\left[ \\frac{\\kappa}{\\tau_{syn}} \\frac{\\tau_{syn}}{N} \\sum_{j \\in G_i} w_{j \\rightarrow i}(t) \\sum_{l^j} \\delta (t - t^j_{l^j} - t_a) \\right] \\\\\n",
    "    & = dt \\cdot  \\underbrace{- \\left[ \\frac{g_{syn, i}}{\\tau_{syn}} \\right] }_{A} + dt \\cdot \\left[ \\underbrace{\\frac{1}{N}}_{B} \\underbrace{\\frac{\\kappa}{\\tau_{syn}}}_{C} \\underbrace{\\tau_{syn}}_{D} \\underbrace{\\sum_{j \\in G_i} w_{j \\rightarrow i}(t) \\sum_{l^j} \\delta (t - t^j_{l^j} - t_a)}_{E} \\right] \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code implementation ( of (`Sexc` and `Sinh`) OR $g_{syn, i}$ ) \n",
    "\n",
    "```python\n",
    "## Line 46 in `get_stationary_states_arange_x_homogeneousNetwork.py`\n",
    "## (Anthony) - Initialize various system parameters via the function call \n",
    "################################################################################\n",
    "STDPon, N, N_STN, VR, tauVT, VTspike, VTRest, tau_spike, V_spike, Vexc, Vinh, tauNoise, noiseIntensities, synaptic_offset_after_spike, tauSyn, dt, Tmax, t, recordedSpikes, kSave, StepsTauSynDelaySTNSTN, StepsTauSynDelayGPeGPe, StepsTauSynDelayGPeSTN, StepsTauSynDelaySTNGPe, a_delaySteps, b_delaySteps, c_delaySteps, delayedSpikingNeurons, numberOfDelayedTimeSteps , est_Spike_Times, switchOffSpikeTimes, basicFilterSpikingNeurons, lastSpikeTimeStep, evenPriorLastSpikeTimeStep, kWeightOutput, NeuronIndices, start_time, borderForScaningForSpikeValues, borderForScaningNeuronsPassingSpikingThreshold, STDPAlreadyOn = functions_sim.initialize_system( system_parameters )\n",
    "\n",
    "## Line 51-52 in `get_stationary_states_arange_x_homogeneousNetwork.py`\n",
    "## (Anthony) - Initialize various parameters for the nodes\n",
    "################################################################################\n",
    "# apply initial conditions\n",
    "Vrest , tau , v, s, Snoise, VT, Vnoise =  functions_sim.set_initial_conditions_for_nodes( system_parameters )\n",
    "\n",
    "## Line 182-185 in `get_stationary_states_arange_x_homogeneousNetwork.py`\n",
    "## (Anthony) - Extract the conductance for excitatory synapses and inhibitory synapses\n",
    "################################################################################\n",
    "# first column of s contains values for exc. conductances\n",
    "# second column values for inhibitory conducances\n",
    "Sexc=s[:,0]\n",
    "Sinh=s[:,1]\n",
    "```\n",
    "- This section shows two different function calls to initialize the system and nodes' parameters. Respectively, `functions_sim.initialize_system()` and `functions_sim.set_initial_conditions_for_nodes()`.\n",
    "- `s` is returned from the `functions_sim.set_initial_conditions_for_nodes()` call, then in line 182-185, the Nx2 ndarray array is split by excitatory and inhibitory synapses for convenience later. \n",
    "- `Sexc` $\\equiv$ \"Excitatory synapse Conductance\" --> This variable is updated by a dynamic function, so this ndarray is used to hold the values.\n",
    "- `Sinh` $\\equiv$ \"Inhibitory synapse Conducatance\" --> This variable is updated by a dynamic function, so this ndarray is used to hold the values. \n",
    "\n",
    "\n",
    "\n",
    "``` python\n",
    "## Line 473-476 in `functions_sim.py`\n",
    "## (Anthony) - Get values from dictionary: tauSynExc = 1.0, tauSynInh = 3.3, tauNoise = 1.0 millisecond\n",
    "################################################################################\n",
    "# synaptic time scales\n",
    "tauSynExc=system_parameters['tauSynExc'] # synaptic time constant [ms] according to Ebert et al. 2014\n",
    "tauSynInh=system_parameters['tauSynInh']\n",
    "tauNoise = system_parameters['tauNoise']\n",
    "\n",
    "## Line 483-485 in `functions_sim.py`\n",
    "################################################################################\n",
    "# preevaluate synaptic quantities to speed up simulation\n",
    "synaptic_offset_after_spike=1./(float(N)) # mV\n",
    "tauSyn=np.array([1/tauSynExc,1/tauSynInh])\n",
    "\n",
    "## Line 190-193 in `get_stationary_states_arange_x_homogeneousNetwork.py`\n",
    "## (Anthony) - `s_Offset` is component A of the reordered equation 7 above.\n",
    "################################################################################\n",
    "# calculate right-hand site of equation for membrane potential\n",
    "v_Offset=ne.evaluate('1/tau*((Vrest-v) +(Vnoise-v)*Snoise+(Vexc-v)*Sexc+(Vinh-v)*Sinh)')\n",
    "# synaptic conductances\n",
    "s_Offset=-np.multiply(s,tauSyn)\n",
    "\n",
    "## Line 212 in `get_stationary_states_arange_x_homogeneousNetworki.py`\n",
    "## (Anthony) - Partial update of the conductance at current Euler step.\n",
    "################################################################################\n",
    "s=ne.evaluate('s+dt*s_Offset')\n",
    "```\n",
    "- The values are read in from the Python dictionary `system_parameters`, of which has the following key-value pairs.\n",
    "    - `tauSynExc` = 1.0 ms\n",
    "    - `tauSynInh` = 3.3 ms\n",
    "    - `tauNoise` = 1.0 ms\n",
    "- `synaptic_offset_after_spike`: is equivalent to component B of the reordered equation 7 above. \n",
    "- `tauSyn`: \n",
    "    - An ndarray of length 2, holding the inverse time-constant for excitatory and inhibitory synapses respectively.\n",
    "    - This is equivalent to the denominator of component C of the reordered equation 7 above.\n",
    "- `s_Offset`: \n",
    "    - Equivalent to component A of the reordered equation 7 above.\n",
    "- `s`: \n",
    "    - The synaptic conductance `s` is partially updated by multiplying component A by time-step `dt` and added to the value of `s` from the previous time-step.\n",
    "    - Component B, C, (D), E are part of the second part of the synaptic conductance update. (Component D is is parenthesized because it seems to be missing from the code implementation.)\n",
    "- kappa\n",
    "    - It scales the maximal coupling strengh, $\\kappa = 8 \\, mS/cm^2$ (in the paper), however, the code set this value as `400`.\n",
    "    - The scaling up of \n",
    "\n",
    "\n",
    "``` python\n",
    "## Line 339-340 in `get_stationary_states_arange_x_homogeneousNetworki.py`\n",
    "## (Anthony) - Later matrix multiplication would sum all the weights of spiked presynaptic partners of each neuron.\n",
    "################################################################################\n",
    "# spikes are arriving and cause upades of synaptic conductances\n",
    "activeConnectionWeights=scipy.sparse.csc_matrix( ( np.array(cMatrix[synapsesOfArrivingSpikes[1:,1],synapsesOfArrivingSpikes[1:,0]])[0], (synapsesOfArrivingSpikes[1:,1],synapsesOfArrivingSpikes[1:,0]) ), shape=(N,N) )\n",
    "\n",
    "## Line 29-34 in `functions_pars.py`\n",
    "## (Anthony) - This is equivalent to what the paper terms \"maximal coupling strength (kappa)\", which the paper initialized at 8 mS/cm^2 for excitatory STN neurons.\n",
    "################################################################################\n",
    "# exc coupling\n",
    "system_parameters.update({'cMaxExc': 400})\n",
    "system_parameters.update({'cExcInit': 200.0})\n",
    "# inh coupling\n",
    "system_parameters.update({'cMaxInh': 0.0})\n",
    "system_parameters.update({'cInhInit': 0.0})\n",
    "\n",
    "## Line 660-663 in `functions_sim.py`\n",
    "################################################################################\n",
    "# synaptic time scales\n",
    "tauSynExc=system_parameters['tauSynExc']  # ms # synaptic time constant [ms] according to Ebert et al. 2014\n",
    "tauSynInh=system_parameters['tauSynInh']  # ms\n",
    "tauNoise = system_parameters['tauNoise']  # ms\n",
    "\n",
    "## Line 798-799 in `get_stationary_states_arange_x_homogeneousNetworki.py`\n",
    "## (Anthony) - Placeholder that will be updated soon.\n",
    "################################################################################\n",
    "# create filter to read out exc/inh neurons\n",
    "basicFilterSpikingNeurons=np.zeros( (N,2) )\n",
    "\n",
    "## Line 806-810 in `functions_sim.py`\n",
    "## (Anthony) - Update the placeholder; equivalent to component C of the reordered equation 7.\n",
    "## (Anthony) - Ignore the `np.ones()` as it is just to initialize an ndarray; it is a multiplicative identity anyways.\n",
    "################################################################################\n",
    "# filter already consideres coupling strengths and synaptic timescales according to differential equations\n",
    "# excitatory weights\n",
    "basicFilterSpikingNeurons[:N_STN,0]=cMaxExc/tauSynExc*np.ones(N_STN)\n",
    "# inhibitory weights\n",
    "basicFilterSpikingNeurons[N_STN:,1]=cMaxInh/tauSynInh*np.ones(N_GPe)\n",
    "```\n",
    "- `activeConnectionWeights` is initialized as a sparse matrix because the weight matrix (`cMatrix`) is sparse. \n",
    "    - `cMatrix` is an ndarray 2D array storing the weight of all pairwise connections - If there isn't a connection, the weight would be 0.\n",
    "- `basicFilterSpikingNeurons` is a 2D ndarray with excitatory synapses in the first column and the inhibitory neuron in the second column.\n",
    "    - The value recorded here is equivalent to component C of the reordered equation 7 above.\n",
    "\n",
    "``` python\n",
    "## Line 342-346 in `get_stationary_states_arange_x_homogeneousNetworki.py`\n",
    "## (Anthony): \n",
    "##   - `synaptic_offset_after_spike` = 1/N = Component B of the reordered equation 7.\n",
    "##   - `activeConnectionWeights` = Component E of the reordered equation 7.\n",
    "##   - `basicFilterSpikingNeurons` = Component C of the reordered equation 7.\n",
    "##   - This addes the second part of the dg update to the g (equivalent to the `s` in the code).\n",
    "##   - HOWEVER!!! --> Component D is mising from the code implementation??? This is problematic for the conductance updates of the inhibitory synapse because `tauSynInh` is not 1.\n",
    "################################################################################\n",
    "# update synaptic weight\n",
    "# this matrix product effectively calculates the sum over weights of active synapses \n",
    "# this sum is then added to 's' while rescaling with 'synaptic_offset_after_spike' = 1/N\n",
    "# first column of s are excitatory and second column are inhibitory synapses\n",
    "s+=synaptic_offset_after_spike*activeConnectionWeights.dot( basicFilterSpikingNeurons )\n",
    "```\n",
    "- Here we combine all components together. \n",
    "    - `synaptic_offset_after_spike` = Component B\n",
    "    - `activeConnectionWeights` = Component E\n",
    "    - `basicFilterSpikingNeurons` = Component C\n",
    "- Conclusion: \n",
    "    - Component D is missing in the code, however, when `tau_syn` = 1, it does not matter as it would be a multiplicative identity.\n",
    "    - **TODO: ??? Ask Justus why is component D missing from the code here? Doesn't this impact the dynamic of how the synaptic conductance for excitatory and inhibitory synapses update at each Euler step?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation 8:\n",
    "![Alt text](image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation 9: \n",
    "![Alt text](image-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\tau_{syn} \\frac{d g_{noise, i}}{d t} & = -g_{noise, i} + \\kappa_{noise} \\tau_{syn} \\sum_{k_i} \\delta (t_{k_i} - t) \\\\\n",
    "\\\\\n",
    "\\implies d g_{noise, i} & = \\left( \\frac{d t}{\\tau_{syn}} \\cdot -g_{noise, i} \\right) + \\left( \\frac{d t}{\\tau_{syn}} \\cdot \\kappa_{noise} \\tau_{syn} \\sum_{k_i}\\delta (t_{k_i} - t) \\right) \\\\\n",
    "    & = dt \\left[ \\left( \\frac{1}{\\tau_{syn}} \\cdot -g_{noise, i} \\right) + \\left( \\frac{1}{\\tau_{syn}} \\cdot \\kappa_{noise} \\tau_{syn} \\sum_{k_i}\\delta (t_{k_i} - t) \\right) \\right] \\\\\n",
    "    & = dt \\left[ \\left( \\frac{-g_{noise, i}}{\\tau_{syn}} \\right) + \\left( \\frac{1}{\\tau_{syn}} \\cdot \\kappa_{noise} \\tau_{syn} \\sum_{k_i}\\delta (t_{k_i} - t) \\right) \\right] \\\\\n",
    "    & = dt \\left[ \\left( \\underbrace{\\frac{-g_{noise, i}}{\\tau_{syn}}}_{A} \\right) + \\left( \\underbrace{\\kappa_{noise}}_{B} \\sum_{k_i} \\underbrace{\\delta (t_{k_i} - t)}_{C} \\right) \\right] \\\\\n",
    "    & = dt \\left[ \\left( \\underbrace{\\frac{-g_{noise, i}}{\\tau_{syn}}}_{\\tau_{syn} = 1 ms} \\right) + \\left( \\underbrace{\\kappa_{noise}}_{=0.026 \\frac{mS}{cm^2}} \\sum_{k_i} \\underbrace{\\delta (t_{k_i} - t)}_{\\text{Dirac Delta Function}} \\right) \\right] \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code implementation: \n",
    "\n",
    "```python\n",
    "## Line 191 in `get_stationary_states_arange_x_homogeneousNetwork.py'\n",
    "################################################################################\n",
    "v_Offset=ne.evaluate('1/tau*((Vrest-v) +(Vnoise-v)*Snoise+(Vexc-v)*Sexc+(Vinh-v)*Sinh)')\n",
    "\n",
    "## Line 195 in `get_stationary_states_arange_x_homogeneousNetwork.py'\n",
    "################################################################################\n",
    "Snoise_Offset=-Snoise/tauNoise  # tauNoise is set as a constant = 1.0 millisecond\n",
    "\n",
    "## Line 213 in `get_stationary_states_arange_x_homogeneousNetwork.py'\n",
    "################################################################################\n",
    "Snoise=ne.evaluate('Snoise+dt*Snoise_Offset')\n",
    "\n",
    "## Line 216-218 in `get_stationary_states_arange_x_homogeneousNetwork.py'\n",
    "################################################################################\n",
    "# update noise conductances if Poisson spikes arrive\n",
    "# spikeArrival[ currentSlotInSpikeArrival ] cotains the number of arriving spikes, i.e. 0, 1, ...\n",
    "Snoise+=noiseIntensities/tauNoise*spikeArrival[ currentSlotInSpikeArrival ]\n",
    "```\n",
    "\n",
    "- `tauNoise` is denoted as $\\tau_{syn}$ in the paper, and both parameters are set to 1.0 millisecond.\n",
    "- Line 195 aligns with A of the reordered equation.\n",
    "- Line 218: \n",
    "    - `noiseIntensities`:\n",
    "        - The code sets this value to be `1.3`.\n",
    "        - $\\kappa_{noise} = 0.026 \\frac{mS}{cm^2}$ in B corresponds to this variable. \n",
    "        - The code's value is scaled by a factor of 50x from the value stated by the paper: `0.026 * 50 = 1.3`\n",
    "    - `tauNoise`:\n",
    "        - As seen in the derivation of equation 9 from the paper, $\\tau_{syn}$ has been cancelled out and thus I believe should NOT be included in the code line 218.\n",
    "        - `tauNoise = 1`, even though I believe is mathematically incorrect, the results should be okay due to 1 being a multiplicative identity. HOWEVER, if the value were to ever be changed via the `functions_pars.py` to any other value (suppose we are trying to model something with slower synaptic time-constant), then this simulation would not be correct.\n",
    "        - TODO: Discuss and ask the author if this should be fixed.\n",
    "    - `spikeArrival`: \n",
    "        - The `spikeArrival` ndarray records the number of spiked presynaptic partners of each neuron.\n",
    "        - It models the Dirac Delta Function (or C) of the re-organized equation 9 above.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "## Line 479-480 in 'functions_sim.py`\n",
    "################################################################################\n",
    "noiseIntensities=np.full( N, system_parameters['noiseSTN'] )\n",
    "noiseIntensities[N_STN:]=np.full( N_GPe, system_parameters['noiseGPe'] )\n",
    "\n",
    "## Line 61-62 in 'functions_pars.py`\n",
    "################################################################################\n",
    "system_parameters.update({'noiseSTN': 1.3})\n",
    "system_parameters.update({'noiseGPe': 2.0})\n",
    "```\n",
    "- This shows how `noiseIntensities` is created. It is just an ndarray of size `N = N_STN + N_GPe = 1000 + 2`.\n",
    "- The first `N_STN=1000` elements of this ndarray has the value `noiseSTN = 1.3`.\n",
    "- The last 2 elements of this ndarray has the value `noiseGPe = 2.0`\n",
    "- ??? Does this mean that if we were to mode an inhibitory neuron and want to scale by 1/50, then the actual intensity would be `0.04`?  \n",
    "\n",
    "\n",
    "### Conclusion: \n",
    "- We see that `tauNoise` is incorrectly included in line 218, however, because the variable is set as a constant 1, it does not create issue with the simulation.\n",
    "- We see that $\\kappa_{noise}$ is being modeled as conductance and scaled by a factor of 50x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter values: \n",
    "![Alt text](image-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
